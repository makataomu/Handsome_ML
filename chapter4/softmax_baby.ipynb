{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(x_instance, class_weights):\n",
    "    return np.dot(x_instance, class_weights)\n",
    "\n",
    "#  true_labes is 0 and 1. 1 if class belongs\n",
    "# loss = 0\n",
    "# for x_instance in X:\n",
    "#     all_scores = [score(x_instance, class_weights) for class_weights in all_weights]\n",
    "#     exp_scores = [exp(class_score) for class_score in all_scores]\n",
    "#     sum_of_exp_scores = sum(exp_scores)\n",
    "#     probs = [exp_score / sum_of_exp_scores for exp_scores in exp_scores]\n",
    "\n",
    "#     true labels and probs should be of the same order\n",
    "#     cross_entropies = true_labels[c] * probs[c] for c in range(len(true_labels))\n",
    "#     loss += sum(cross_entropies)\n",
    "# loss = loss / X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(X, weights):\n",
    "    all_scores = [score(X, class_weights) for class_weights in weights]\n",
    "    exp_scores = [np.exp(class_score) for class_score in all_scores]\n",
    "    sum_of_exp_scores = sum(exp_scores)\n",
    "    probs = [exp_score / sum_of_exp_scores for exp_score in exp_scores]\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_val = list(range(10))\n",
    "neg_val = list(range(10, 20))\n",
    "data = {}\n",
    "y = []\n",
    "\n",
    "for i in range(20):\n",
    "    if i % 2 == 0:\n",
    "        data[i] = pos_val\n",
    "        y.append(0)\n",
    "    else:\n",
    "        data[i] = neg_val\n",
    "        y.append(1)\n",
    "\n",
    "X = pd.DataFrame(data).T.to_numpy()\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(16.719513079034975), np.float64(5.323414319644163)]\n",
      "[10 11 12 13 14 15 16 17 18 19] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(54.92085789799475), np.float64(-16.38188614056866)]\n",
      "[0 1 2 3 4 5 6 7 8 9] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(16.719513079034975), np.float64(5.323414319644163)]\n",
      "[10 11 12 13 14 15 16 17 18 19] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(54.92085789799475), np.float64(-16.38188614056866)]\n",
      "[0 1 2 3 4 5 6 7 8 9] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(16.719513079034975), np.float64(5.323414319644163)]\n",
      "[10 11 12 13 14 15 16 17 18 19] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(54.92085789799475), np.float64(-16.38188614056866)]\n",
      "[0 1 2 3 4 5 6 7 8 9] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(16.719513079034975), np.float64(5.323414319644163)]\n",
      "[10 11 12 13 14 15 16 17 18 19] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(54.92085789799475), np.float64(-16.38188614056866)]\n",
      "[0 1 2 3 4 5 6 7 8 9] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(16.719513079034975), np.float64(5.323414319644163)]\n",
      "[10 11 12 13 14 15 16 17 18 19] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(54.92085789799475), np.float64(-16.38188614056866)]\n",
      "[0 1 2 3 4 5 6 7 8 9] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(16.719513079034975), np.float64(5.323414319644163)]\n",
      "[10 11 12 13 14 15 16 17 18 19] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(54.92085789799475), np.float64(-16.38188614056866)]\n",
      "[0 1 2 3 4 5 6 7 8 9] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(16.719513079034975), np.float64(5.323414319644163)]\n",
      "[10 11 12 13 14 15 16 17 18 19] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(54.92085789799475), np.float64(-16.38188614056866)]\n",
      "[0 1 2 3 4 5 6 7 8 9] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(16.719513079034975), np.float64(5.323414319644163)]\n",
      "[10 11 12 13 14 15 16 17 18 19] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(54.92085789799475), np.float64(-16.38188614056866)]\n",
      "[0 1 2 3 4 5 6 7 8 9] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(16.719513079034975), np.float64(5.323414319644163)]\n",
      "[10 11 12 13 14 15 16 17 18 19] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(54.92085789799475), np.float64(-16.38188614056866)]\n",
      "[0 1 2 3 4 5 6 7 8 9] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(16.719513079034975), np.float64(5.323414319644163)]\n",
      "[10 11 12 13 14 15 16 17 18 19] [[ 0.5088024  -0.64403217  1.80725518  0.81431167  0.35968123  0.29822828\n",
      "  -1.81953666  1.07063348  1.02410053  0.40069055]\n",
      " [ 0.08402963 -0.81567655 -1.22580633 -1.25409739  0.30170287 -0.65865107\n",
      "  -0.85042489 -0.16311124  1.01977673  1.3917282 ]]\n",
      "[np.float64(54.92085789799475), np.float64(-16.38188614056866)]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "classes = list(set(y))\n",
    "weights = np.random.randn(len(classes), X.shape[1])\n",
    "\n",
    "true_labels = [0 for c in classes]\n",
    "gradients = np.array([np.zeros(X.shape[1]) for c in classes])\n",
    "\n",
    "# как вариант можно отделать нужную часть X и работать со всем дф в numpy\n",
    "# predict_proba(X, weights)\n",
    "for x_instance, label in zip(X, y):\n",
    "    probs = predict_proba(x_instance, weights)\n",
    "\n",
    "    true_labels[label] = 1\n",
    "\n",
    "    for c in classes:\n",
    "        gradients[c] += (probs[c] - true_labels[c]) * x_instance \n",
    "\n",
    "gradients = gradients / X.shape[0]\n",
    "\n",
    "# gradient shows direction in which the weights should be adjusted to minimize the loss.\n",
    "weights = weights - learning_rate * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights -= learning_rate * gradient"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
